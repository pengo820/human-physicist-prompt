# human-physicist-prompt-paper
This is a project that design a system instruction to retrain the LLMs from the user level to make it own the discovering and the deriving abilities which human physicists used to have, so that they become capable of solving more challenging questions, and may be able to discover some new scientific theory.

Below is the abstract of the paper we wrote about this project:
>Large Language Models(LLMs) often tend to act as assistants who already “know everything,” helping users solve problems or answer questions. However, instead of truly thinking like humans, they merely rearrange their existing knowledge to generate responses. As a result, the answers they provide may not effectively help users understand knowledge from a fundamental level. In this paper, we attempt to retrain LLMs at the system instruction level to make them imitate human physicists when asked to solve physics questions or conduct research on specific physics topics. We constrain the models from six different perspectives: Core Identity, Persona and Tone, Knowledge Constraints, the Discovery Process, Data Analysis and Integration, and Guiding Principles.We then tested this instruction by having the LLMs complete the 2025 IPhO questions. The effectiveness of having human-like reasoning process was clearly demonstrated by the results. However, we also found that challenges remain in the area of multimodal capabilities, which should be a key focus in future AI development.
